---
title: "Chance in Games"
author: "Sonya Eason and Sarah Ouda"
format: pdf
editor: source
---

##Libraries

```{r}
library(dplyr)

```


To determine how skill and chance play a role in team performance, and also predict who would win 2024 March Madness, we decided to take the following approach:

1)  identify a rational metric of team skill.

2)  model team wins as a function of skill under informative priors.

3)  determine to what extent wins could be explained by team skill and how much was left to chance. determine who would win March Madness 2024 under our model.

Data used and preprocessing: 
In addition to using the provided data from the 2024 season for all teams in the March Madness Tournament, we gathered historical game log data for the 2022 and 2023 seasons as well. 

How we developed our skil


**Identify a Rational Metric of Team Skill**

here

```{r}

library(readr)
#teams <- read_csv("bbdata23-24/Basketball_dataset.xlsx - Teams.csv")

#akron <- read_csv("bbdata23-24/Basketball_dataset.xlsx - Akron(56).csv")
```



Read in data


##combining data

```{r}
# Define the folder path where your CSV files are stored
folder_path <- "bbdata23-24"

# Get a list of all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read all CSV files into a list of data frames
dataframes <- lapply(csv_files,function(file) {
  df <- read.csv(file)  # Read the CSV file
  
   # Rename the column "X" to "W.L" if it exists
  if ("X" %in% colnames(df)) {
    colnames(df)[colnames(df) == "X"] <- "W.L"
  }
  
  # Extract the team name from the file name
  team_name <- gsub("Basketball_dataset\\.xlsx - (.*)\\(.*\\.csv", "\\1", basename(file))
  
  # Add the team name as a new column
  df$Team <- team_name
  
  df$source_file <- basename(file)  # Add the file name as a column
  return(df)
})


# Find the union of all column names across data frames
all_columns <- Reduce(union, lapply(dataframes, colnames))

# Ensure all data frames have the same columns
dataframes <- lapply(dataframes, function(df) {
  missing_columns <- setdiff(all_columns, colnames(df))
  df[missing_columns] <- NA  # Add missing columns with NA
  df <- df[, all_columns]    # Reorder columns to match
  return(df)
})

# Combine all data frames into one
combined_2023 <- do.call(rbind, dataframes)

# View the combined data frame
head(combined_2023)
dim(combined_2023)
```


```{r}
# Define the folder path where your CSV files are stored
folder_path <- "data21-22"

# Get a list of all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read all CSV files into a list of data frames
dataframes <- lapply(csv_files,function(file) {
  df <- read.csv(file)  # Read the CSV file
  
  
   # Extract the team name from the file name
  team_name <- gsub("_(21-22_.*\\.csv)", "", basename(file))
  team_name <- gsub("_", " ", team_name)  # Replace underscores with spaces for readability
  
  # Add the team name as a new column
  df$Team <- team_name
  

  
  df$source_file <- basename(file)  # Add the file name as a column
  return(df)
})


# Find the union of all column names across data frames
all_columns <- Reduce(union, lapply(dataframes, colnames))

# Ensure all data frames have the same columns
dataframes <- lapply(dataframes, function(df) {
  missing_columns <- setdiff(all_columns, colnames(df))
  df[missing_columns] <- NA  # Add missing columns with NA
  df <- df[, all_columns]    # Reorder columns to match
  return(df)
})

# Combine all data frames into one
combined_2021 <- do.call(rbind, dataframes)

# View the combined data frame
head(combined_2021)
dim(combined_2021)

```


```{r}
# Define the folder path where your CSV files are stored
folder_path <- "data22-23"

# Get a list of all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read all CSV files into a list of data frames
dataframes <- lapply(csv_files,function(file) {
  df <- read.csv(file)  # Read the CSV file
  
   # Extract the team name from the file name
  team_name <- gsub("(\\s|_)?22-23_.*\\.csv", "", basename(file))
  team_name <- gsub("_", " ", team_name)  # Replace underscores with spaces
  
  # Add the team name as a new column
  df$Team <- team_name
  

  df$source_file <- basename(file)  # Add the file name as a column
  return(df)
})


# Find the union of all column names across data frames
all_columns <- Reduce(union, lapply(dataframes, colnames))

# Ensure all data frames have the same columns
dataframes <- lapply(dataframes, function(df) {
  missing_columns <- setdiff(all_columns, colnames(df))
  df[missing_columns] <- NA  # Add missing columns with NA
  df <- df[, all_columns]    # Reorder columns to match
  return(df)
})

# Combine all data frames into one
combined_2022 <- do.call(rbind, dataframes)

# View the combined data frame
head(combined_2022)
```

Df names:
2021-2022: combined_2021
2022-2023: combined_2022
2023-2024: combined_2023




```{r}
# Define the columns to retain
target_columns <- c("G", "Date", "Opponent", "W.L", "Tm", "Opp", "Team", "source_file")

# Function to filter and align columns
filter_columns <- function(df, target_columns) {
  # Retain only the target columns present in the data frame
  df <- df[, intersect(colnames(df), target_columns), drop = FALSE]
  
  # Add missing columns with NA
  missing_columns <- setdiff(target_columns, colnames(df))
  df[missing_columns] <- NA
  
  # Reorder columns to match target_columns
  df <- df[, target_columns, drop = FALSE]
  return(df)
}

# Filter and align columns in each combined data frame
combined_2023 <- filter_columns(combined_2023, target_columns)
combined_2022 <- filter_columns(combined_2022, target_columns)
combined_2021 <- filter_columns(combined_2021, target_columns)

# Combine the filtered data frames into one
bbcombined <- rbind(combined_2023, combined_2022, combined_2021)
bbcombined$Team <- gsub("Northwestern 22-23 36.csv", "Northwestern", bbcombined$Team)


# View the final combined data frame
head(bbcombined)
dim(bbcombined)
```

```{r}
unique(bbcombined$Team)

```

Combined Name: bbcombined





##skill task

To develop the skill metric, it was of utmost importance to determine whether a team performed well but also performed consistently. A good performance, could in theory appear to be based on skill, but it would be wrong to give skill points to a team if that appearingly skilled performance came out of a performance that was a high score based on luck. For this reason, we decided to utilize a skill metric that would give weight to consistently and performance. Consistency in this case can be considered to be a function of variance. 
$$
skill = consistency \ * performance
$$

$$
consistency = 1-\frac{variance}{k}

$$
Consider k to be a constant that normalizes so the consistency is relative across teams. We chose our normalizing constant to be the max variance a team had in performance metric. 

There were two main metrics with which skill could be calculated: win fraction and point differentials. Win fraction refers to the amount of wins out of total games a team played in a given time interval. Point differentials refer to the value of the team's earned points minus their opponent's points per game. For example, if the team lead by 6 points, they would have a +6 point differential for a specific game but if they were behind by 4 points, they would have a -4 point differential. 

$$
skill = (1-\frac{var(win\ fraction)}{max(var(win fraction))})* mean(win fraction)
$$
$$
skill = (1-\frac{var(point\ differential)}{max(var(point\  differential))})* mean(point \ differential)
$$



```{r}
combined_2023 <- combined_2023 |>
  select(Date, X, Tm, Opp, source_file )
```

```{r}
combined_2023 |>
  group_by(source_file, Date) |>
  count(X)
```



```{r}
# need to calculcate this for all 

point_diff_akron <- akron$Tm - akron$Opp
point_diff_alabama <- alabama$Tm - alabama$Opp


POINTDIFF = NULL
POINTDIFF = c(POINTDIFF, point_diff_akron)

POINTDIFF = c(POINTDIFF, point_diff_alabama)
```

```{r}
(1-var(point_diff_akron)/(var(point_diff_akron)+100))*(mean(point_diff_akron))
```

## Metropolis-Hastings Algorithm

$x_i$ the skill metric for team i.

$yi$ the performance of team i, win 1, lose 1

$\beta_1$: a coefficient revealing how $x_i$ impacts probability a team wins

$$
p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) =
\prod_{i=1}^n \ (\frac{1}{(1+exp(\beta_0 + \beta_1 * x_i)})^{y_i} * (1-\frac{1}{(1+exp(\beta_0 + \beta_1 * x_i))})^{1-y_i}
$$



$$
p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) =
 \ (\frac{1}{1+exp(\beta_0 + \beta_1 * x_i)})^{\sum_{i=1}^n y_i} * (1-\frac{1}{1+exp(\beta_0 + \beta_1 * x_i)})^{n-\sum_{i=1}^n y_i}
$$

$$
p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) =
 \ (\frac{1}{1+exp(\beta_0 + \beta_1 * x_i)})^{n\bar{y}} * (1-\frac{1}{1+exp(\beta_0 + \beta_1 * x_i)})^{n-n\bar{y}}
$$


$$
log(p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1)) =  {n\bar{y}} * log(\frac{1}{1+exp(\beta_0 + \beta_1 * x_i)}) +({n-n\bar{y}})* log((1-\frac{1}{1+exp(\beta_0 + \beta_1 * x_i)}))
$$

$$
p(\beta_1\ |\ y_1, ...,y_n, \ x_1, ..., x_n,  \beta_0)  \propto \ p(y_1, ..., y_n, \ x_1, ..., x_n,  \beta_0, \beta_1)  = p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1)
$$


$$

p(y_1, ..., y_n, \ x_1, ..., x_n,  \beta_0, \beta_1)  = p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) * p(x_1, ..., x_n,  \beta_0, \beta_1)

$$


$$
 p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) * p(x_1, ..., x_n,  \beta_0, \beta_1) \propto p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) * p( \beta_1)
$$


```{r}
set.seed(4)

logLikelihood = function(beta0, beta1) {
  l = 1 + exp(beta0 + (beta1 * x))
  n*y_bar*log(1/l)+(n-n*y_bar)*log(1-1/l)
}

logPrior = function(beta0, beta1) {
  dnorm(beta0, 0, sqrt(1000), log = TRUE) + 
    dnorm(beta1, 0, sqrt(1000), log = TRUE)
}

logPosterior = function(beta0, beta1) {
  logLikelihood(beta0, beta1) + logPrior(beta0, beta1)
}


BETA0 = NULL
BETA1 = NULL

##do I want to utilize sigma
SIGMA2 = NULL

accept1 = 0
accept2 = 0
accept3 = 0

y_bar = mean(y)
n = length(y)

S = 500

beta0_s = 0.1
beta1_s = 10
sigma2_s = 1
for (s in 1:S) {
  
  ## propose and update beta0
  beta0_proposal = rnorm(1, mean = beta0_s, .5)
   log.r = logPosterior(beta0_proposal, beta1_s, sigma2_s) - 
     logPosterior(beta0_s, beta1_s, sigma2_s)
   
   if(log(runif(1)) < log.r)  {
    beta0_s = beta0_proposal
    accept1 = accept1 + 1 
   }
   
   BETA0 = c(BETA0, beta0_s)
   
   ## propose and update beta1
    beta1_proposal = rnorm(1, mean = beta1_s, .5)
   log.r = logPosterior(beta0_s, beta1_proposal, sigma2_s) - 
     logPosterior(beta0_s, beta1_s, sigma2_s)
   
   if(log(runif(1)) < log.r)  {
    beta1_s = beta1_proposal
    accept2 = accept2 + 1 
   }
   
   BETA1 = c(BETA1, beta1_s)
   
   ## propose and update sigma2
   ### note: sigma2 is positive only, we want to only propose positive values
   sigma2_proposal = 1 / rgamma(1, shape = 1, sigma2_s)
   log.r = logPosterior(beta0_s, beta1_s, sigma2_proposal) - 
     logPosterior(beta0_s, beta1_s, sigma2_s) + 
     dinvgamma(sigma2_proposal, 1, sigma2_s, log = TRUE) - 
     dinvgamma(sigma2_s, 1, sigma2_proposal, log = TRUE) 
   
   if(log(runif(1)) < log.r)  {
    sigma2_s = sigma2_proposal
    accept3 = accept3 + 1 
   }
   
   SIGMA2 = c(SIGMA2, sigma2_s)
   
}
```

