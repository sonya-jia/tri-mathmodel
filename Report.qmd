---
title: "Chance in Games"
author: "Sonya Eason and Sarah Ouda"
format: pdf
editor: source
---

##Libraries

```{r}
library(dplyr)

```


To determine how skill and chance play a role in team performance, and also predict who would win 2024 March Madness, we decided to take the following approach:

1)  identify a rational metric of team skill.

2)  model team wins as a function of skill under informative priors.

3)  determine to what extent wins could be explained by team skill and how much was left to chance. determine who would win March Madness 2024 under our model.

Data Used & Background Research: 
In addition to using the provided data from the 2024 season for all teams in the March Madness Tournament, we gathered historical game log data for the 2022 and 2023 seasons as well (https://www.sports-reference.com/cbb/seasons/men/2022-school-stats.html). Our system for quanitifying skill was inspired by this article: https://www.siam.org/publications/siam-news/articles/feeling-lucky-the-relative-roles-of-skill-and-chance-in-sports/. 




**Identify a Rational Metric of Team Skill**

here

```{r}

library(readr)
teamsf <- read_csv("Basketball_dataset.xlsx - Teams.csv")

#akron <- read_csv("bbdata23-24/Basketball_dataset.xlsx - Akron(56).csv")
```



Read in data


##combining data

```{r}
# Define the folder path where your CSV files are stored
folder_path <- "bbdata23-24"

# Get a list of all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read all CSV files into a list of data frames
dataframes <- lapply(csv_files,function(file) {
  df <- read.csv(file)  # Read the CSV file
  
   # Rename the column "X" to "W.L" if it exists
  if ("X" %in% colnames(df)) {
    colnames(df)[colnames(df) == "X"] <- "W.L"
  }
  
  # Extract the team name from the file name
  team_name <- gsub("Basketball_dataset\\.xlsx - (.*)\\(.*\\.csv", "\\1", basename(file))
  
  # Add the team name as a new column
  df$Team <- team_name
  
  df$source_file <- basename(file)  # Add the file name as a column
  return(df)
})


# Find the union of all column names across data frames
all_columns <- Reduce(union, lapply(dataframes, colnames))

# Ensure all data frames have the same columns
dataframes <- lapply(dataframes, function(df) {
  missing_columns <- setdiff(all_columns, colnames(df))
  df[missing_columns] <- NA  # Add missing columns with NA
  df <- df[, all_columns]    # Reorder columns to match
  return(df)
})

# Combine all data frames into one
combined_2023 <- do.call(rbind, dataframes)

# View the combined data frame
head(combined_2023)
dim(combined_2023)
```


```{r}
# Define the folder path where your CSV files are stored
folder_path <- "data21-22"

# Get a list of all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read all CSV files into a list of data frames
dataframes <- lapply(csv_files,function(file) {
  df <- read.csv(file)  # Read the CSV file
  
  
   # Extract the team name from the file name
  team_name <- gsub("_(21-22_.*\\.csv)", "", basename(file))
  team_name <- gsub("_", " ", team_name)  # Replace underscores with spaces for readability
  
  # Add the team name as a new column
  df$Team <- team_name
  

  
  df$source_file <- basename(file)  # Add the file name as a column
  return(df)
})


# Find the union of all column names across data frames
all_columns <- Reduce(union, lapply(dataframes, colnames))

# Ensure all data frames have the same columns
dataframes <- lapply(dataframes, function(df) {
  missing_columns <- setdiff(all_columns, colnames(df))
  df[missing_columns] <- NA  # Add missing columns with NA
  df <- df[, all_columns]    # Reorder columns to match
  return(df)
})

# Combine all data frames into one
combined_2021 <- do.call(rbind, dataframes)

# View the combined data frame
head(combined_2021)
dim(combined_2021)

```


```{r}
# Define the folder path where your CSV files are stored
folder_path <- "data22-23"

# Get a list of all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read all CSV files into a list of data frames
dataframes <- lapply(csv_files,function(file) {
  df <- read.csv(file)  # Read the CSV file
  
   # Extract the team name from the file name
  team_name <- gsub("(\\s|_)?22-23_.*\\.csv", "", basename(file))
  team_name <- gsub("_", " ", team_name)  # Replace underscores with spaces
  
  # Add the team name as a new column
  df$Team <- team_name
  

  df$source_file <- basename(file)  # Add the file name as a column
  return(df)
})


# Find the union of all column names across data frames
all_columns <- Reduce(union, lapply(dataframes, colnames))

# Ensure all data frames have the same columns
dataframes <- lapply(dataframes, function(df) {
  missing_columns <- setdiff(all_columns, colnames(df))
  df[missing_columns] <- NA  # Add missing columns with NA
  df <- df[, all_columns]    # Reorder columns to match
  return(df)
})

# Combine all data frames into one
combined_2022 <- do.call(rbind, dataframes)

# View the combined data frame
head(combined_2022)
```

Df names:
2021-2022: combined_2021
2022-2023: combined_2022
2023-2024: combined_2023




```{r}
# Define the columns to retain
target_columns <- c("G", "Date", "Opponent", "W.L", "Tm", "Opp", "Team", "source_file")

# Function to filter and align columns
filter_columns <- function(df, target_columns) {
  # Retain only the target columns present in the data frame
  df <- df[, intersect(colnames(df), target_columns), drop = FALSE]
  
  # Add missing columns with NA
  missing_columns <- setdiff(target_columns, colnames(df))
  df[missing_columns] <- NA
  
  # Reorder columns to match target_columns
  df <- df[, target_columns, drop = FALSE]
  return(df)
}

# Filter and align columns in each combined data frame
combined_2023 <- filter_columns(combined_2023, target_columns)
combined_2022 <- filter_columns(combined_2022, target_columns)
combined_2021 <- filter_columns(combined_2021, target_columns)

# Combine the filtered data frames into one
bbcombined <- rbind(combined_2023, combined_2022, combined_2021)
bbcombined$Team <- gsub("Northwestern 22-23 36.csv", "Northwestern", bbcombined$Team)


# View the final combined data frame
head(bbcombined)
dim(bbcombined)
```

```{r}
unique(bbcombined$Team)

```

Combined Name: bbcombined





##skill task

To develop the skill metric, it was of utmost importance to determine whether a team performed well but also performed consistently. A good performance, could in theory appear to be based on skill, but it would be wrong to give skill points to a team if that appearingly skilled performance came out of a performance that was a high score based on luck. For this reason, we decided to utilize a skill metric that would give weight to consistently and performance. Consistency in this case can be considered to be a function of variance. 
$$
skill = consistency \ * performance
$$

$$
consistency = 1-\frac{variance}{k}
$$
Consider k to be a constant that normalizes so the consistency is relative across teams. We chose our normalizing constant to be the max variance a team had in performance metric. 

There were two main metrics with which skill could be calculated: win fraction and point differentials. Win fraction refers to the amount of wins out of total games a team played in a given time interval. Point differentials refer to the value of the team's earned points minus their opponent's points per game. For example, if the team lead by 6 points, they would have a +6 point differential for a specific game but if they were behind by 4 points, they would have a -4 point differential. 

$$
skill = (1-\frac{var(win\ fraction)}{max(var(win fraction))})* mean(win fraction)
$$
$$
skill = (1-\frac{var(point\ differential)}{max(var(point\  differential))})* mean(point \ differential)
$$

```{r}
library(dplyr)

# Convert the date column to Date format and extract the month abbreviation
mod_df <- bbcombined %>%
  mutate(
    date = as.Date(Date, format = "%a %b %d %Y"),  # Convert to Date format
    month_abbr = format(date, "%b"),  # Extract month abbreviation (e.g., "Nov")
    period = case_when(
      month_abbr %in% c("Aug", "Sep", "Oct", "Nov", "Dec") ~ "first",  # August to November
      month_abbr %in% c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul") ~ "second",  # January to July
      TRUE ~ NA_character_  # Handle any cases that might not fit
    )
  )

```


```{r}
mod_df %>%
  group_by(Team)
```


```{r}
clean_mod_df <- mod_df |>
  filter(!is.na(Tm))
```

```{r}
win_fraction <- clean_mod_df %>%
  group_by(Team, source_file) %>%
  summarise(
    total_games = n(),  # Count total games
    total_wins = sum(W.L == "W"),  # Count wins
    win_fraction = total_wins / total_games  # Calculate fraction of wins
  )
```
```{r}
var_win <- win_fraction |>
  group_by(Team) |>
  summarize(
    mean = mean(win_fraction),
    variance = var(win_fraction))

team_var <- var_win$variance
team_mean <- var_win$mean
```

```{r}
skill <- (1-team_var/max(team_var))*(team_mean)
```

```{r}
hi <-
clean_mod_df |>
  mutate(point_diff = Tm - Opp)

hi <- hi |>
  filter(!is.na(point_diff))


h <- hi |>
  group_by(Team) |>
  summarise(mean_point_diff = mean(point_diff),
    variance_point_diff = var(point_diff))
```


```{r}
teampt_var <- h$variance_point_diff
teampt_mean <- h$mean_point_diff
```


```{r}
skill_pt <- (1-teampt_var/max(teampt_var))*(teampt_mean)
```





## Metropolis-Hastings Algorithm

We believe the probability of winning a game to be a function of skill. This is how we will predict who wins 2024. The other question we will answer is how much is skill explanatory of wins. We must start by building a model that quantifies skill in game wins and seeing what variability can not be explained by skill differential. For those other factors not accounted for are chance-based factors.

Since teams have different skill levels. It is also clear that the probability a team wins a game varies as a function of this skill level.

Consider the binary variable of a team winning a game. In this case, the probability a team wins a game, $\theta_t$ varies as a function of skill. 

$$
Y_i \sim binary(\theta_t)
$$
We define this as below. 
$$
\theta_t = \frac{1}{1+exp(\beta_0 + \beta_1 * x_i)}
$$

$x_i$ the skill metric for team i.

$yi$ the performance of team i, win 1, lose 1

$\beta_1$: a coefficient revealing how $x_i$ impacts probability a team wins

$$
p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1) =
\prod_{i=1}^n \ (\frac{1}{(1+exp(\beta_0 + \beta_1 * x_i)})^{y_i} * (1-\frac{1}{(1+exp(\beta_0 + \beta_1 * x_i))})^{1-y_i}
$$
We will define things on a log scale to avoid issues in numerical computation. 

$$
log (p(y_1 ...y_n\ |\ x_1, ..., x_n,  \beta_0, \beta_1)) = {\sum_{i=1}^n \ [\ y_i*log(\frac{1}{(1+exp(\beta_0 + \beta_1 * x_i)}) +\\
(1-y_i)*log(1-\frac{1}{(1+exp(\beta_0 + \beta_1 * x_i))})]}
$$


```{r}

```



In order to build a distribution for $p(\beta_0, \beta_1 | \vec{y}, \vec{x})$, which is how we will land on the coefficients for our model, we need to set priors on the coefficients. 

Since, we don't know much about skill's effect on performance, we will use diffuse priors. In this case, normal distributions with variance 1000. 

$$
p(\beta_0, \beta_1) = dnorm(\beta_0, 0, sqrt(1000))* dnorm(\beta_1, 0, sqrt(1000))
$$
$$
log(p(\beta_0, \beta_1)) = log(dnorm(\beta_0, 0, sqrt(1000))) + log(dnorm(\beta_1, 0, sqrt(1000)))
$$

We will chose a symmetric target distribution for sampling. If we choose a target that is irreducible, aperiodic, and recurrent, Ergodic theorem promises that our Markov chain will yield a stationary target distribution which is in this case a posterior defined by $p(\beta_0, \beta_1 | \vec{y}, \vec{x})$. 

To determine if we accept a proposed value, we will utilize the following acceptance rate. 


$$
\frac{p(\beta_0^*, \beta_1^s |\ y_1, ...,y_n, \ x_1, ..., x_n)}{p(\beta_0^s, \beta_1^s |\ y_1, ...,y_n, \ x_1, ..., x_n)}
$$


$$
\frac{p(\beta_0^{s+1}, \beta_1^s |\ y_1, ...,y_n, \ x_1, ..., x_n)}{p(\beta_0^{s+1}, \beta_1^* |\ y_1, ...,y_n, \ x_1, ..., x_n)}
$$
Since we do not have posteriors yet, we will weaponize the fact that this ratio is equivalent to the likelihood times posterior ratio. 

$$
\frac{posterior(new \ state)}{posterior(old\ state)} = \frac{prior(new\ state) * likelihood(new\ state)}{prior(old\ state) * likelihood(old\ state)}
$$


```{r eval = FALSE}
set.seed(4)

logLikelihood = function(beta0, beta1) {
  l = 1 + exp(beta0 + (beta1 * x))
sum(y*log(1/l)+(1-y)*log(1-1/l))
}

logPrior = function(beta0, beta1) {
  dnorm(beta0, 0, sqrt(1000), log = TRUE) + 
    dnorm(beta1, 0, sqrt(1000), log = TRUE)
}

logPosterior = function(beta0, beta1) {
  logLikelihood(beta0, beta1) + logPrior(beta0, beta1)
}


BETA0 = NULL
BETA1 = NULL


accept1 = 0
accept2 = 0

x = skill
S = 10000

beta0_s = 0
beta1_s = 0
for (s in 1:S) {
  
  ## propose and update beta0
  beta0_proposal = rnorm(1, mean = beta0_s, 1)
   log.r = logPosterior(beta0_proposal, beta1_s) - 
     logPosterior(beta0_s, beta1_s)
   
   if(log(runif(1)) < log.r)  {
    beta0_s = beta0_proposal
    accept1 = accept1 + 1 
    
    if (s%%100 == 0)
    {
         BETA0 = c(BETA0, beta0_s)
    }
   }

   
   ## propose and update beta1
    beta1_proposal = rnorm(1, mean = beta1_s, .5)
   log.r = logPosterior(beta0_s, beta1_proposal) - 
     logPosterior(beta0_s, beta1_s)
   
   if(log(runif(1)) < log.r)  {
    beta1_s = beta1_proposal
    accept2 = accept2 + 1 
        if (s%%100 == 0)
    {
         BETA1 = c(BETA1, beta1_s)
    }
   }
   
   BETA1 = c(BETA1, beta1_s)

   
   
}
```

